on: [ "push", "pull_request", "workflow_dispatch" ]

jobs:
  build_wheels:
    runs-on: "ubuntu-24.04"
    container:
      image: "archlinux/archlinux:base-devel-20250614.0.365658"
      options: "--workdir /workspace"
    strategy:
      fail-fast: false
      matrix:
        package: [ "cadquery-ocp", "lib3mf" ]
        build_type: [ "Release", "Debug" ]
        include:
          - build_type: "Debug"
            cflags: "-Og -g"
            cxxflags: "-Og -g"
            ldflags: "-Og -g -gsource-map=inline"
          - build_type: "Release"
            cflags: "-O3"
            cxxflags: "-O3"
            ldflags: "-O3"

          - package: "cadquery-ocp"
            build_type: "Release"
            ldflags: "-O1" # XXX: See repair_wasm.py invocation in CMakeLists.txt
          - package: "cadquery-ocp"
            build_type: "Debug"
            ldflags: "-Og -g -gsource-map=inline -gseparate-dwarf"
    steps:
      - run: "pacman -Syu --noconfirm git && git config --global --add safe.directory '*'"
      - uses: "actions/checkout@v4"
        with:
          fetch-depth: 0 # Fetch all history for caching purposes

      - uses: "actions/cache@v4"
        id: "cache"
        with:
          path: |
            ${{ matrix.package }}/build
            !${{ matrix.package }}/build/*/_deps/*-src
            ~/.cache
            ${{ matrix.package }}/wheelhouse/*.whl
          key: "build_wheels-${{ matrix.package }}-${{ matrix.build_type }}-${{ github.ref_name }}-${{ hashFiles('**/CMakeLists.txt', '**/*.cmake', '**/pyproject.toml', '**/*.py') }}"
          restore-keys: |
            build_wheels-${{ matrix.package }}-${{ matrix.build_type }}-${{ github.ref_name }}-
          # build_wheels-${{ matrix.package }}-${{ matrix.build_type }}-master-
          # build_wheels-${{ matrix.package }}-${{ matrix.build_type }}-

      - id: "wheel_up_to_date"
        run: ".github/scripts/wheel_up_to_date.sh ${{ matrix.package }}"

      - id: "xbuildenv_data"
        run: ".github/scripts/xbuildenv_data.sh"
      - uses: "actions/setup-python@v5"
        if: "steps.wheel_up_to_date.outputs.skip_build != 'true'"
        with:
          python-version: "${{ steps.xbuildenv_data.outputs.python_version }}"
          cache: 'pip' # caching pip dependencies

      - working-directory: "${{ matrix.package }}"
        if: "steps.wheel_up_to_date.outputs.skip_build != 'true'"
        run: | # Install dependencies and build the package
          pip install -r requirements.txt
          pyodide xbuildenv install "${{ steps.xbuildenv_data.outputs.xbuildenv_version }}"
          pip install $(python -c 'import tomllib; cfg = tomllib.load(open("pyproject.toml", "rb")); print(*cfg["build-system"]["requires"])')
          pyodide build --exports=whole_archive
        env:
          SKBUILD_CMAKE_BUILD_TYPE: "${{ matrix.build_type }}"
          SKBUILD_BUILD_TOOL_ARGS: "-d;explain;-v" # Useful to debug if caches are not working as expected
          CFLAGS: "${{ matrix.cflags }}"
          CXXFLAGS: "${{ matrix.cxxflags }}"
          LDFLAGS: "${{ matrix.ldflags }}"
          _FORCE_OLD_SOURCES: "TRUE" # XXX: Force old sources for the caches to be effective (CI-only issue due to redownloading of sources as it sometimes fails if sources are cached)
        timeout-minutes: 310 # This ensures that the following steps are run even if builds take way too long (mainly uploading caches for faster future builds!)

      - uses: "actions/upload-artifact@v4"
        with:
          name: "wheel-${{ matrix.package }}-${{ matrix.build_type }}"
          path: "${{ matrix.package }}/wheelhouse/*.whl"

      - if: "failure()" # Save cache even on failures
        uses: "actions/cache/save@v4"
        with:
          key: "${{ steps.cache.outputs.cache-primary-key }}"
          path: |
            ${{ matrix.package }}/build
            !${{ matrix.package }}/build/*/_deps/*-src
            ~/.cache
            ${{ matrix.package }}/wheelhouse/*.whl

      - if: "always()"  # Upload cache and wheels as an artifact for debugging
        uses: "actions/upload-artifact@v4"
        with:
          name: "cache-${{ matrix.package }}-${{ matrix.build_type }}"
          include-hidden-files: true
          path: |
            ${{ matrix.package }}/build
            !${{ matrix.package }}/build/*/_deps/*-src
            ~/.cache
            ${{ matrix.package }}/wheelhouse/*.whl

  build_package_index:
    needs: "build_wheels"
    runs-on: "ubuntu-24.04"
    steps:
      - uses: "actions/checkout@v4"
        with:
          ref: "gh-pages"

      - uses: "actions/download-artifact@v4"
        with:
          pattern: "wheel-*"
          path: "_wheels"

      - run: |
          wget "https://raw.githubusercontent.com/yeicor/OCP.wasm/${{github.ref}}/util/package_index.py" -O _package_index.py
          find # For debugging
          python3 _package_index.py --wheels . _wheels --output .  # Overwrites matching versions (warnings are ok!)
          rm -rf _wheels _package_index.py

      - uses: "actions/upload-artifact@v4"
        with:
          name: "package-index"
          path: "."

  test_build123d_integration: # Test build123d integration using the wheels and package index generated above
    needs: "build_package_index"
    runs-on: "ubuntu-24.04"
    steps:
      - uses: "actions/checkout@v4"

      - uses: "actions/download-artifact@v4"
        with:
          name: "package-index"
          path: "package-index"

      - id: "xbuildenv_data"
        run: ".github/scripts/xbuildenv_data.sh"
      - uses: "actions/setup-python@v5"
        with:
          python-version: "${{ steps.xbuildenv_data.outputs.python_version }}"
          cache: 'pip' # caching pip dependencies

      - working-directory: "build123d"
        run: |
          set -ex 
          
          # Update package index links to point to the local files
          to_remove="https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/"
          package_index_folder="$(realpath $(pwd)/../package-index)/"
          find "$package_index_folder" -type f -exec sed -i "s|${to_remove}|file://${package_index_folder}|g" {} \;
          
          # Set up the Pyodide test environment
          pip install -r ../requirements.txt
          pyodide xbuildenv install "${{ steps.xbuildenv_data.outputs.xbuildenv_version }}"
          pyodide venv .venv-pyodide
          . .venv-pyodide/bin/activate
          
          # Install build123d and run tests
          pip install -vvv --index-url "file://$package_index_folder" --extra-index-url "https://pypi.org/simple" -r requirements-stable.txt
          python test.py | tee -a test.log
          
          # Check if ALL tests passed (last line of the log should be "OK")
          if tail -n 1 test.log | grep -q "OK"; then
            echo "All tests passed."
          else
            echo "Some tests failed. Check the log for details."
            exit 1
          fi

      - uses: "actions/upload-artifact@v4"
        if: "always()"
        with:
          name: "test-build123d-integration-log"
          path: "build123d/test.log"

  deploy_package_index:
    needs: "test_build123d_integration"
    if: "github.ref == 'refs/heads/master'"
    runs-on: "ubuntu-24.04"
    steps:
      - uses: "actions/checkout@v4"
        with:
          ref: "gh-pages"

      - uses: "actions/download-artifact@v4"
        with:
          name: "package-index"
          path: "."

      - run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -v .
          git commit -m "Update package index" || echo "No changes to commit"
          git push origin gh-pages

  # TODO: deploy_wheels_to_pypi: (doesn't support WebAssembly)
